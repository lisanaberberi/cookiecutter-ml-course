{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Taxi Trip Duration Prediction\n",
    "\n",
    "This notebook demonstrates a clean ML pipeline for predicting taxi trip durations using NYC Yellow Taxi data from October-November 2023.\n",
    "\n",
    "## Pipeline Steps\n",
    "1. Data preprocessing (using separate script)\n",
    "2. Model training\n",
    "3. Model evaluation\n",
    "4. Results visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import our custom preprocessing functions\n",
    "\n",
    "from taxi_ride.data.preprocess_data import (\n",
    "    get_project_paths, \n",
    "    load_pickle, \n",
    "    dump_pickle,\n",
    "    run_preprocessing\n",
    ")\n",
    "\n",
    "# Let's manually verify and set the correct paths\n",
    "# Since we're in notebooks/, we need to go up one level to project root\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.dirname(NOTEBOOK_DIR)  # Go up one level\n",
    "\n",
    "print(f\"\\nCurrent notebook directory: {NOTEBOOK_DIR}\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Construct correct paths manually\n",
    "CORRECT_RAW_DATA_DIR = os.path.join(PROJECT_ROOT, 'data', 'raw')\n",
    "CORRECT_PROCESSED_DATA_DIR = os.path.join(PROJECT_ROOT, 'data', 'processed')\n",
    "\n",
    "print(f\"\\nCorrected paths:\")\n",
    "print(f\"Raw data directory: {CORRECT_RAW_DATA_DIR}\")\n",
    "print(f\"Processed data directory: {CORRECT_PROCESSED_DATA_DIR}\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(CORRECT_RAW_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(CORRECT_PROCESSED_DATA_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"\\nDirectory structure:\")\n",
    "print(f\"Raw data exists: {os.path.exists(CORRECT_RAW_DATA_DIR)}\")\n",
    "print(f\"Processed data exists: {os.path.exists(CORRECT_PROCESSED_DATA_DIR)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "We'll use the `preprocess_data.py` script to load and prepare our data from URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_preprocessing(\n",
    "    raw_data_path=CORRECT_RAW_DATA_DIR,\n",
    "    dest_path=CORRECT_PROCESSED_DATA_DIR,\n",
    "    dataset=\"green\",         # or \"yellow\"\n",
    "    train_month=\"2023-10\",\n",
    "    val_month=\"2023-11\",\n",
    "    test_month=\"2023-12\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Download and Save Raw Data\n",
    "# from taxi_ride.data.preprocess_data import (\n",
    "#     get_data_path, \n",
    "#     load_parquet, \n",
    "#     save_parquet\n",
    "# )\n",
    "\n",
    "# # Configuration\n",
    "# BASE_URL = \"https://d37ci6vzurychx.cloudfront.net/trip-data\"\n",
    "# OUTPUT_DIR = CORRECT_RAW_DATA_DIR\n",
    "# DATASET = \"green\"  # Change to \"yellow\" if needed\n",
    "# MONTHS = [\"2023-10\", \"2023-11\", \"2023-12\"]\n",
    "\n",
    "# #print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "# print(f\"Dataset: {DATASET}\")\n",
    "# print(f\"Months: {MONTHS}\")\n",
    "\n",
    "# # Ensure output directory exists\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# # Download each month's data using existing functions\n",
    "# downloaded_files = []\n",
    "\n",
    "# for month in MONTHS:\n",
    "#     # Use get_data_path to construct the URL\n",
    "#     url = get_data_path(BASE_URL, DATASET, month)\n",
    "    \n",
    "#     # Construct local output path\n",
    "#     filename = f\"{DATASET}_tripdata_{month}.parquet\"\n",
    "#     output_path = os.path.join(OUTPUT_DIR, filename)\n",
    "    \n",
    "#     print(f\"\\nProcessing {filename}...\")\n",
    "#     print(f\"  URL: {url}\")\n",
    "#     #print(f\"  Local path: {output_path}\")\n",
    "    \n",
    "#     try:\n",
    "#         # Use load_parquet to download data\n",
    "#         df = load_parquet(url)\n",
    "#         print(f\"  ✓ Loaded data: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
    "        \n",
    "#         # Use save_parquet to save locally\n",
    "#         save_parquet(df, output_path)\n",
    "        \n",
    "#         # Show basic info\n",
    "#         print(f\"  Columns: {len(df.columns)}\")\n",
    "        \n",
    "#         downloaded_files.append(output_path)\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"  ✗ Error processing {filename}: {e}\")\n",
    "\n",
    "# print(f\"\\n✓ Download completed!\")\n",
    "# print(f\"Files downloaded: {len(downloaded_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxi_ride.data.preprocess_data import load_pickle\n",
    "\n",
    "PROCESSED_DATA_DIR = os.path.join(\"..\", \"data\", \"processed\")\n",
    "\n",
    "X_train, y_train = load_pickle(os.path.join(PROCESSED_DATA_DIR, \"train.pkl\"))\n",
    "X_val, y_val = load_pickle(os.path.join(PROCESSED_DATA_DIR, \"val.pkl\"))\n",
    "dv = load_pickle(os.path.join(PROCESSED_DATA_DIR, \"dv.pkl\"))\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Number of features: {len(dv.feature_names_)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics on target variable\n",
    "print(\"Training Data Duration Statistics:\")\n",
    "print(f\"Mean: {y_train.mean():.2f} minutes\")\n",
    "print(f\"Median: {np.median(y_train):.2f} minutes\")\n",
    "print(f\"Std Dev: {y_train.std():.2f} minutes\")\n",
    "print(f\"Min: {y_train.min():.2f} minutes\")\n",
    "print(f\"Max: {y_train.max():.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of trip durations\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_train, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Duration (minutes)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Trip Durations')\n",
    "plt.axvline(y_train.mean(), color='red', linestyle='--', label=f'Mean: {y_train.mean():.1f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(y_train, vert=True)\n",
    "plt.ylabel('Duration (minutes)')\n",
    "plt.title('Box Plot of Trip Durations')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train linear regression model\n",
    "print(\"Training Linear Regression model...\")\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, dataset_name=\"\"):\n",
    "    \"\"\"Evaluate model and print metrics.\"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Metrics:\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  R²:   {r2:.4f}\")\n",
    "    \n",
    "    return y_pred, rmse, mae, r2\n",
    "\n",
    "# Evaluate on training set\n",
    "y_train_pred, _, _, _ = evaluate_model(lr, X_train, y_train, \"Training Set\")\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred, val_rmse, val_mae, val_r2 = evaluate_model(lr, X_val, y_val, \"Validation Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions vs actual\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Distribution comparison\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(y_val, label='Actual', alpha=0.6, bins=50, color='blue')\n",
    "sns.histplot(y_val_pred, label='Predicted', alpha=0.6, bins=50, color='red')\n",
    "plt.xlabel('Duration (minutes)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Validation Set: Actual vs Predicted Distribution')\n",
    "plt.legend()\n",
    "\n",
    "# Scatter plot\n",
    "plt.subplot(1, 2, 2)\n",
    "# Sample for visualization (plot every 10th point)\n",
    "sample_idx = np.arange(0, len(y_val), 10)\n",
    "plt.scatter(y_val[sample_idx], y_val_pred[sample_idx], alpha=0.3, s=10)\n",
    "plt.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2, label='Perfect prediction')\n",
    "plt.xlabel('Actual Duration (minutes)')\n",
    "plt.ylabel('Predicted Duration (minutes)')\n",
    "plt.title(f'Validation Set: Predictions vs Actual\\nR² = {val_r2:.4f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "residuals = y_val - y_val_pred\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Residual (minutes)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Residuals')\n",
    "plt.axvline(0, color='red', linestyle='--', label='Zero error')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_val_pred[sample_idx], residuals[sample_idx], alpha=0.3, s=10)\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted Duration (minutes)')\n",
    "plt.ylabel('Residual (minutes)')\n",
    "plt.title('Residual Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nModel Type: Linear Regression\")\n",
    "print(f\"Number of Features: {X_train.shape[1]}\")\n",
    "print(f\"Training Samples: {X_train.shape[0]:,}\")\n",
    "print(f\"Validation Samples: {X_val.shape[0]:,}\")\n",
    "print(f\"\\nValidation Performance:\")\n",
    "print(f\"  RMSE: {val_rmse:.4f} minutes\")\n",
    "print(f\"  MAE:  {val_mae:.4f} minutes\")\n",
    "print(f\"  R²:   {val_r2:.4f}\")\n",
    "print(f\"\\nMean Absolute Percentage Error: {(val_mae / y_val.mean() * 100):.2f}%\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_path = os.path.join(PROJECT_ROOT,\"models\", \"linear_regression_model.pkl\")\n",
    "with open(model_path, \"wb\") as f_out:\n",
    "    pickle.dump(lr, f_out)\n",
    "\n",
    "print(f\"Model saved to: {model_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlops-env)",
   "language": "python",
   "name": "mlops-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
