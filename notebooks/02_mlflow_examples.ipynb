{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of using MLflow as experiment tracking and model registry\n",
    "\n",
    "MLflow setup- Scenario 1:\n",
    "* Tracking server: no\n",
    "* Backend store: local filesystem\n",
    "* Artifacts store: local filesystem, i.e. /mlruns\n",
    "\n",
    "The experiments can be explored locally by launching the MLflow UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current notebook directory: /home/lisanab/fujitsu_laptop_files/MLOps/cookiecutter/cookiecutter-ml-course/notebooks\n",
      "Project root: /home/lisanab/fujitsu_laptop_files/MLOps/cookiecutter/cookiecutter-ml-course\n",
      "\n",
      "Corrected paths:\n",
      "Models artifacts directory: /home/lisanab/fujitsu_laptop_files/MLOps/cookiecutter/cookiecutter-ml-course/models\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import mlflow \n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import our custom preprocessing functions\n",
    "\n",
    "from taxi_ride.data.preprocess_data import (\n",
    "    get_project_paths\n",
    ")\n",
    "\n",
    "# Get project paths from pyproject.toml - this should point to project root\n",
    "paths = get_project_paths()\n",
    "RAW_DATA_DIR = paths[\"RAW_DATA_DIR\"]\n",
    "PROCESSED_DATA_DIR = paths[\"PROCESSED_DATA_DIR\"]\n",
    "\n",
    "\n",
    "# Let's manually verify and set the correct paths\n",
    "# Since we're in notebooks/, we need to go up one level to project root\n",
    "NOTEBOOK_DIR = os.getcwd()\n",
    "PROJECT_ROOT = os.path.dirname(NOTEBOOK_DIR)  # Go up one level\n",
    "\n",
    "print(f\"\\nCurrent notebook directory: {NOTEBOOK_DIR}\")\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Construct correct paths manually\n",
    "MODELS_ARTIFACTS = os.path.join(PROJECT_ROOT, 'models')\n",
    "MLFLOW_TRACKING_URI = os.path.join(PROJECT_ROOT, 'models', 'mlruns')\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(MLFLOW_TRACKING_URI, exist_ok=True)\n",
    "\n",
    "# Set MLflow tracking URI to project root's models directory\n",
    "mlflow.set_tracking_uri(f\"file://{MLFLOW_TRACKING_URI}\")\n",
    "\n",
    "print(f\"\\nCorrected paths:\")\n",
    "print(f\"Models artifacts directory: {MODELS_ARTIFACTS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'file:///home/lisanab/fujitsu_laptop_files/MLOps/cookiecutter/cookiecutter-ml-course/models/mlruns'\n"
     ]
    }
   ],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='file:///home/lisanab/fujitsu_laptop_files/MLOps/cookiecutter/cookiecutter-ml-course/models/mlruns/840068150784448506', creation_time=1763558260303, experiment_id='840068150784448506', last_update_time=1763558260303, lifecycle_stage='active', name='my-experiment-1', tags={}>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an experiment and logging a new run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
      "0                5.1               3.5                1.4               0.2   \n",
      "1                4.9               3.0                1.4               0.2   \n",
      "2                4.7               3.2                1.3               0.2   \n",
      "3                4.6               3.1                1.5               0.2   \n",
      "4                5.0               3.6                1.4               0.2   \n",
      "5                5.4               3.9                1.7               0.4   \n",
      "6                4.6               3.4                1.4               0.3   \n",
      "7                5.0               3.4                1.5               0.2   \n",
      "8                4.4               2.9                1.4               0.2   \n",
      "9                4.9               3.1                1.5               0.1   \n",
      "\n",
      "   target  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "5       0  \n",
      "6       0  \n",
      "7       0  \n",
      "8       0  \n",
      "9       0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lisanab/fujitsu_laptop_files/MLOps/cookiecutter/course-env/lib/python3.12/site-packages/mlflow/data/dataset_source_registry.py:148: UserWarning: Failed to determine whether UCVolumeDatasetSource can resolve source information for 'scikit‚Äëlearn:load_iris'. Exception: \n",
      "  return _dataset_source_registry.resolve(\n",
      "/home/lisanab/fujitsu_laptop_files/MLOps/cookiecutter/course-env/lib/python3.12/site-packages/mlflow/data/dataset_source_registry.py:148: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n",
      "/home/lisanab/fujitsu_laptop_files/MLOps/cookiecutter/course-env/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run‚ÄØID: a912c4072b244a79a69ad3164e621f97\n",
      "üèÉ View run sedate-mule-532 at: http://127.0.0.1:5000/#/experiments/268956126154477783/runs/a912c4072b244a79a69ad3164e621f97\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/268956126154477783\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.data\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# 1. Load the Iris dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "feature_names = load_iris().feature_names\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df[\"target\"] = y\n",
    "\n",
    "print(df.head(10))\n",
    "\n",
    "# 2. Create a Dataset object for MLflow\n",
    "dataset = mlflow.data.from_pandas(\n",
    "    df,\n",
    "    source=\"scikit‚Äëlearn:load_iris\",   # you can pick a descriptive string\n",
    "    name=\"iris_dataset\",\n",
    "    targets=\"target\"\n",
    "\n",
    ")\n",
    "\n",
    "# 3. Start an MLflow run and log dataset, model, etc.\n",
    "mlflow.set_experiment(\"iris‚Äëexperiment‚Äëwith‚Äëdataset\")\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log the dataset as input\n",
    "    mlflow.log_input(dataset, context=\"training\")\n",
    "\n",
    "    # Log parameters\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Train model\n",
    "    lr = LogisticRegression(**params, max_iter=200)  # max_iter increased for safety\n",
    "    lr.fit(X, y)\n",
    "\n",
    "    # Predict and log metric\n",
    "    #Input: 4 numeric features (flower measurements)\n",
    "    #Output: A class label (0, 1, or 2) representing which iris species the flower belongs to, e.g. Iris setosa, iris versicolor, or iris virginica.\n",
    "    y_pred = lr.predict(X)\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "    # Log the model (sklearn) with a small input_example for inference\n",
    "    mlflow.sklearn.log_model(\n",
    "        lr,\n",
    "        name=\"model\",\n",
    "        input_example=X[:5]\n",
    "    )\n",
    "\n",
    "    print(f\"Run‚ÄØID: {mlflow.active_run().info.run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='mlflow-artifacts:/723872913022227632', creation_time=1763558435991, experiment_id='723872913022227632', last_update_time=1763558435991, lifecycle_stage='active', name='my-experiment-1', tags={'mlflow.experimentKind': 'custom_model_development'}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1763558317564, experiment_id='0', last_update_time=1763558317564, lifecycle_stage='active', name='Default', tags={'mlflow.experimentKind': 'custom_model_development'}>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.exceptions import MlflowException\n",
    "\n",
    "try:\n",
    "    client.search_registered_models()\n",
    "except MlflowException:\n",
    "    print(\"It's not possible to access the model registry :(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2: A cross-functional team with one data scientist working on an ML model\n",
    "\n",
    "\n",
    "MLflow setup:\n",
    "- tracking server: yes, local server\n",
    "- backend store: sqlite database\n",
    "- artifacts store: local filesystem\n",
    "\n",
    "The experiments can be explored locally by accessing the local tracking server.\n",
    "\n",
    "To run this example you need to launch the mlflow server locally by running the following command in your terminal:\n",
    "\n",
    "`mlflow server --backend-store-uri sqlite:///backend.db`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://127.0.0.1:5000'\n"
     ]
    }
   ],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3: Multiple data scientists working on multiple ML models\n",
    "\n",
    "MLflow setup:\n",
    "* Tracking server: yes, remote server (EC2).\n",
    "* Backend store: postgresql database.\n",
    "* Artifacts store: s3 bucket.\n",
    "\n",
    "The experiments can be explored by accessing the remote server.\n",
    "```bash\n",
    "mlflow server \\\n",
    "  --backend-store-uri \"postgresql://<USER>:<PASSWORD>@<HOST>:<PORT>/<DB_NAME>\" \\\n",
    "  --artifacts-destination \"s3://<YOUR_BUCKET_NAME>/mlflow-artifacts\" \\\n",
    "  --host 0.0.0.0 \\\n",
    "  --port 5000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "#set the environmental vars to allow 'mlflow_user' to track experiments using MLFlow\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "# IMPORTANT CONSTANTS TO DEFINE\n",
    "\n",
    "# Remote MLFlow server\n",
    "MLFLOW_REMOTE_SERVER=\"your-mlflow-server.com\"  # e.g., http://mlflow.your-domain.com:5000\n",
    "#Set the MLflow server and backend and artifact stores\n",
    "mlflow.set_tracking_uri(MLFLOW_REMOTE_SERVER)\n",
    "\n",
    "# for direct API calls via HTTP we need to inject credentials\n",
    "MLFLOW_TRACKING_USERNAME = 'lisana.berberi@kit.edu'\n",
    "MLFLOW_TRACKING_PASSWORD =  getpass.getpass()  # inject password by typing manually\n",
    "# for MLFLow-way we have to set the following environment variables\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = MLFLOW_TRACKING_USERNAME\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = MLFLOW_TRACKING_PASSWORD\n",
    "#os.environ[\"LOGNAME\"] = MLFLOW_TRACKING_USERNAME # User who is logging the experiment, if not set then the default value of a user will be your local username\n",
    "\n",
    "# Name of the experiment (e.g. name of the  code repository)\n",
    "mlflow.set_experiment(\"green-taxi-duration-x\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlops-env)",
   "language": "python",
   "name": "mlops-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
